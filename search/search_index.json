{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Data Scraping Application \ud83d\udd78\ufe0f","text":""},{"location":"#overview","title":"Overview","text":"<p>The Data Scraping Application is a collaborative project developed by students between Hochschule Augsburg, Germany, and LNU University, Sweden, with the supervision of Softwerk AB company. This application allows users to scrape data from specific websites by inputting a URL, selecting scraping options, and retrieving structured data output. \ud83d\udcca</p>"},{"location":"#project-features","title":"Project Features \u2728","text":"<ul> <li>Web Scraping Functionality: Users can input a URL to scrape data.</li> <li>Multiple Scraping Options: Select from various scraping methods to meet your needs.</li> <li>User-Friendly Interface: Modern and user-friendly front-end built using React.js.</li> <li> <p>Data Processing: Possible implementation of language models to summarize and clean scraped data.</p> </li> <li> <p>\u2705 Scrapes static websites using Requests and BeautifulSoup</p> </li> <li>\u2705 Scrapes dynamic websites using Selenium</li> <li>\u2705 Option to clean scraped data</li> <li>\u2705 Preview or save the scraped data as a <code>.txt</code> file</li> <li>\u2705 Reliable and secure REST API with JWT Token</li> </ul>"},{"location":"#tech-stack","title":"Tech Stack \ud83d\udee0\ufe0f","text":"<ul> <li>Front-End: React.js, Tailwind CSS</li> <li>Back-End: Flask, SQLite, SQLAlchemy</li> <li>Scraping Libraries: Requests, Beautifulsoup4, Selenium</li> </ul>"},{"location":"#installation","title":"Installation \u26a1","text":"<p>To get started with the Data Scraping Application, clone the repository and install the required dependencies. To run the frontend and backend locally, please refer to our developer documentation. You can navigate to the relevant pages using the top navbar.</p> <pre><code>git clone https://github.com/your-username/data-scraping-application.git\ncd data-scraping-application\n</code></pre> <p></p>   Enjoy Scrapping (\u2741\u00b4\u25e1`\u2741)"},{"location":"Backend/","title":"\ud83d\udda5\ufe0f Backend Documentation","text":""},{"location":"Backend/#overview","title":"\ud83d\ude80 Overview","text":"<p>The backend of the Web Scraping Project is responsible for:</p> <ul> <li> <p>Managing web scraping tasks using Requests, BeautifulSoup or Selenium.</p> </li> <li> <p>Processing and cleaning scraped data .</p> </li> <li> <p>Providing an API to serve the scraped data to the frontend .</p> </li> <li> <p>Handling database operations for storing and retrieving scraped data.</p> </li> </ul>"},{"location":"Backend/#features","title":"\ud83d\udccc Features:","text":"<ul> <li>\u2705 Scrapes static websites using Requests and BeautifulSoup</li> <li>\u2705 Scrapes dynamic websites using Selenium</li> <li>\u2705 Clean scraped data</li> <li>\u2705 Preview or save the scraped data as a <code>.txt</code> file</li> <li>\u2705 Reliable and secure REST API with JWT Token</li> </ul>"},{"location":"Backend/#installation","title":"Installation:","text":"<p>This guide will walk you through setting up and running the backend of the project.</p>"},{"location":"Backend/#1-create-a-virtual-environment-recommended","title":"1\ufe0f\u20e3 Create a Virtual Environment (Recommended)","text":"<p>Using a virtual environment ensures dependencies are managed properly and avoid conflicts.</p> <p>Run the following command to create one:</p> <pre><code>python -m venv venv #python3 for Mac/Linux\n</code></pre> <p>Then activate it:</p> <p>Windows:</p> <pre><code>venv\\Scripts\\activate\n</code></pre> <p>Mac/Linux:</p> <pre><code>source venv/bin/activate\n</code></pre>"},{"location":"Backend/#2-install-the-required-python-version","title":"2\ufe0f\u20e3 Install the Required Python Version","text":"<p>Ensure you have the correct Python version installed.</p> <pre><code>python --version\n</code></pre>"},{"location":"Backend/#3-install-dependencies","title":"3\ufe0f\u20e3 Install Dependencies","text":"<p>After activating the virtual environment, install all required dependencies:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"Backend/#4-code-quality-standards","title":"4\ufe0f\u20e3 Code Quality &amp; Standards","text":"<p>To maintain code quality and consistency, install and configure the following tools:</p> <pre><code>pip install mypy flake8 black pylint\n</code></pre>"},{"location":"Backend/#5-navigate-to-the-backend-directory","title":"5\ufe0f\u20e3 Navigate to the Backend Directory","text":"<p>Move into the backend project folder:</p> <pre><code>cd backend\n</code></pre>"},{"location":"Backend/#6-run-the-backend-server","title":"6\ufe0f\u20e3 Run the Backend Server","text":"<p>Start the Flask application:</p> <p>Windows:</p> <pre><code>python app.py\n</code></pre> <p>Mac/Linux:</p> <pre><code>python3 app.py\n</code></pre>"},{"location":"Backend/#code","title":"Code","text":""},{"location":"Backend/#1-apppy-api-endpoints","title":"1. app.py (API Endpoints):","text":""},{"location":"Backend/#scrape-a-website-scrape","title":"\ud83d\udd0d Scrape a Website (<code>/scrape</code>)","text":""},{"location":"Backend/#overview_1","title":"\ud83d\udccd Overview","text":"<p>This route scrapes a static website using BeautifulSoup or Requests and returns the extracted HTML.</p> <pre><code>@app.route(\"/scrape\", methods=[\"POST\"])\n</code></pre> <p>Defines a route for a specific URL and specifies which HTTP method is allowed</p> <p>this Function calls the scrapes_with_bs4 or scrapes_with_requests function that scrapes static websites and return the data as HTML</p>"},{"location":"Backend/#request-parameters","title":"\ud83d\udce9 Request Parameters","text":"<p>JSON Body (Required Fields)</p> Parameter Type Required Description <code>url</code> <code>string</code> \u2705 Yes The URL of the website to scrape. <code>scraping_method</code> <code>string</code> \u2705 Yes The scraping method: <code>\"requests\"</code>, <code>\"bs4\"</code>, or <code>\"selenium\"</code>. <code>clean_data</code> <code>boolean</code> \u274c No (default: <code>false</code>) Whether to clean the scraped data. <code>company_name</code> <code>string</code> \u2705 Yes (for <code>\"selenium\"</code>) The name of the company (used for Selenium-based scraping). <p>Headers (Optional)</p> Header Type Required Description <code>Authorization</code> <code>string</code> \u274c No JWT token (Required for storing scraping history)."},{"location":"Backend/#processing-steps","title":"\ud83d\udd04 Processing Steps","text":"<ol> <li>Retrieve JSON Data: Extracts the URL, scraping method, and optional parameters from the request.</li> <li>Validation:</li> <li>Ensures the <code>url</code> is provided and starts with <code>https://</code>. If it starts with <code>www.</code>, we will add <code>https://</code></li> <li>Requires <code>scraping_method</code> to be one of <code>\"requests\"</code>, <code>\"bs4\"</code>, or <code>\"selenium\"</code>.</li> <li>If using <code>selenium</code>, <code>company_name</code> is required.</li> <li>Call the Appropriate Scraping Function:</li> <li><code>requests</code> \u2192 <code>scrape_with_requests(url)</code></li> <li><code>bs4</code> \u2192 <code>scrape_with_bs4(url, clean=clean_data)</code></li> <li><code>selenium</code> \u2192 <code>scrape_with_selenium(url, company_name, clean=clean_data)</code></li> <li>Store Scraping History (if JWT token is provided).</li> <li>Return JSON Response with the scraped data.</li> </ol> <p>\ud83d\udcccResponse:</p>"},{"location":"Backend/#success-response","title":"\u2705 Success Response","text":"<p>HTTP Status Code: <code>201 Created</code></p> <pre><code>{\n  \"message\": \"URL Scraped with selenium and content saved\",\n  \"status\": 1,\n  \"scrape_result\": \"&lt;scraped HTML data&gt;\"\n}\n</code></pre> <p>Error Responses</p> <p>The <code>/scrape</code> endpoint may return the following error responses:</p> HTTP Status Code Error Message Description 400 <code>\"error\": \"URL is required\"</code> The <code>url</code> field is missing in the request body. 400 <code>\"error\": \"Scraping method is required\"</code> The <code>scraping_method</code> field is missing in the request body. 400 <code>\"error\": \"Company name is required for Selenium\"</code> The <code>company_name</code> field is required when using <code>\"selenium\"</code> as the <code>scraping_method</code>. 400 <code>\"error\": \"Invalid scraping method\"</code> The provided <code>scraping_method</code> is not recognized (must be <code>\"requests\"</code>, <code>\"bs4\"</code>, or <code>\"selenium\"</code>). 401 <code>\"error\": \"Invalid or missing token\"</code> The request is missing an authorization token or contains an invalid one. 500 <code>\"error\": \"Internal Server Error\"</code> An unexpected server error occurred. <p>\ud83d\udc49 Note: Ensure all required fields are provided in the JSON request body to avoid errors.</p> <p>Why jsonify file ?</p> <p>It's better to return JSON to the frontend because JSON is lightweight, structured, and universally supported by typeScript</p>"},{"location":"Backend/#verify-authentication-auth","title":"\ud83d\udd12 Verify Authentication (<code>/auth</code>)","text":"<p>Method: <code>GET</code> Description: Checks if the provided JWT token is valid.</p>"},{"location":"Backend/#request-headers","title":"\ud83d\udd39 Request Headers","text":"Header Type Required Description Authorization String \u2705 Yes Bearer Token required for authentication."},{"location":"Backend/#responses","title":"\ud83d\udd39 Responses","text":"<p>\u2705 Success (<code>200 OK</code>)</p> <pre><code>{\n  \"message\": \"Token is valid\",\n  \"status\": 1\n}\n</code></pre>"},{"location":"Backend/#login-login","title":"\ud83d\udd11 Login (<code>/login</code>)","text":"<p>Method: <code>POST</code> Description: Authenticates a user and returns a JWT token.</p>"},{"location":"Backend/#request-body-json","title":"\ud83d\udd39 Request Body (JSON)","text":"Parameter Type Required Description <code>email</code> String \u2705 Yes User email. <code>password</code> String \u2705 Yes User password."},{"location":"Backend/#example-request","title":"\ud83d\udd39 Example Request","text":"<pre><code>{\n  \"email\": \"user@example.com\",\n  \"password\": \"password123\"\n}\n</code></pre>"},{"location":"Backend/#responses_1","title":"\ud83d\udd39 Responses","text":"<p>\u2705 Success (<code>200 OK</code>)</p> <pre><code>{\n  \"message\": \"Logged in successfully!\",\n  \"status\": 1,\n  \"token\": \"your_jwt_token\"\n}\n</code></pre> <p>\u274c Errors</p> HTTP Code Message 400 \"error\": \"Email does not exist\" 400 \"error\": \"Incorrect password, try again\""},{"location":"Backend/#jwt-token-authentication","title":"\ud83d\udd11 JWT Token Authentication","text":"<p>In this API, JSON Web Tokens (JWT) are used for user authentication and authorization. JWTs allow secure communication between the client and the server without storing session data.</p> <p>How JWT Works</p> <ol> <li> <p>User Logs In</p> <pre><code>- The user submits their email and password.\n\n- If credentials are valid, a JWT is generated:\n\n```bash\ntoken = jwt.encode(\n   {\n      \"user\": email,  # Store user email in the token\n      \"user_id\": user.id,  # Store user ID in the token\n      \"exp\": datetime.utcnow() + timedelta(seconds=1000)  # Expiration time\n   },\n   app.config[\"SECRET_KEY\"],  # Secret key for encoding\n   algorithm=\"HS256\"\n)\n```\n</code></pre> <p>The token is then sent to the client in the response.</p> </li> <li> <p>Client Sends Token in Requests</p> <ul> <li>The client includes the token in the Authorization header:</li> </ul> <pre><code>Authorization: Bearer &lt;token&gt;\n</code></pre> <ul> <li>The server verifies the token before allowing access.</li> </ul> </li> <li> <p>Server Validates the Token</p> <ul> <li>When a request is received, the token is decoded and verified:</li> </ul> <pre><code>decoded_token = jwt.decode(token, app.config[\"SECRET_KEY\"], algorithms=[\"HS256\"])\nuser_id = decoded_token[\"user_id\"]  # Extract user ID\n</code></pre> <ul> <li>If the token is valid, the request is processed.</li> <li>If the token is expired or invalid, an error is returned.</li> </ul> </li> </ol> <p>Token Expiration &amp; Security</p> <p>Expiration (exp) ensures that tokens are only valid for a limited time (e.g., 1000 seconds).</p> <p>Secret Key (SECRET_KEY) is used for signing and verifying the token to prevent tampering.</p> <p>Bearer Authentication method is used to send the token securely.</p>"},{"location":"Backend/#sign-up-sign-up","title":"\ud83c\udd95 Sign Up (/sign-up)","text":"<p>Method: POST Description: Registers a new user.</p>"},{"location":"Backend/#request-body-json_1","title":"\ud83d\udd39 Request Body (JSON)","text":"Parameter Type Required Description <code>email</code> String \u2705 Yes User email. <code>username</code> String \u2705 Yes User name. <code>password</code> String \u2705 Yes User password. <code>repeat_password</code> String \u2705 Yes Must match the password."},{"location":"Backend/#example-request_1","title":"\ud83d\udd39 Example Request","text":"<pre><code>{\n  \"email\": \"newuser@example.com\",\n  \"userName\": \"newuser\",\n  \"password\": \"password123\",\n  \"repeat_password\": \"password123\"\n}\n</code></pre>"},{"location":"Backend/#responses_2","title":"\ud83d\udd39 Responses","text":"<p>\u2705 Success Response (201 Created)</p> <pre><code>{\n  \"message\": \"Account created successfully!\",\n  \"status\": 1\n}\n</code></pre> <p>\u274c Errors</p> HTTP Code Message 400 \"error\": \"Email already exists\" 400 \"error\": \"Passwords don't match\" 400 \"error\": \"Password must be at least 7 characters\""},{"location":"Backend/#password-hashing","title":"\ud83d\udd10 Password Hashing","text":"<p>In this API, user passwords are securely stored using PBKDF2 (Password-Based Key Derivation Function 2) with SHA-256 hashing. This ensures that passwords are not stored in plain text, enhancing security.</p> <p>How It Works:</p> <ul> <li>When a user signs up, the password is hashed using:</li> </ul> <pre><code>hashed_password = generate_password_hash(password, method=\"pbkdf2:sha256\")\n</code></pre> <ul> <li> <p>The hashed password is stored in the database instead of the plain password.</p> </li> <li> <p>During login, the entered password is hashed again and compared with the stored hash:</p> </li> </ul> <pre><code>check_password_hash(stored_hashed_password, entered_password)\n</code></pre> <ul> <li>If the hashes match, authentication is successful.</li> </ul>"},{"location":"Backend/#view-scraping-history-history","title":"\ud83d\udcdc View Scraping History (<code>/history</code>)","text":"<p>Method: <code>GET</code> Description: Retrieves the scraping history of the logged-in user. Authentication: \u2705 Requires a valid JWT token in the Authorization header.</p>"},{"location":"Backend/#request","title":"\ud83d\udd39 Request","text":"<p>Headers:</p> Header Type Required Description Authorization String \u2705 Yes Bearer token for authentication"},{"location":"Backend/#responses_3","title":"\ud83d\udd39 Responses","text":"<p>\u2705 Success (<code>200 OK</code>)</p> <pre><code>[\n  {\n    \"url\": \"https://example.com\",\n    \"scraped_data\": \"&lt;html&gt;...&lt;/html&gt;\",\n    \"date\": \"2024-03-10 15:30:00\"\n  }\n]\n</code></pre>"},{"location":"Backend/#2-scraperpy","title":"2. scraper.py","text":""},{"location":"Backend/#scrape_with_requests","title":"scrape_with_Requests:","text":""},{"location":"Backend/#description","title":"Description:","text":"<p>Scrapes a static website and returns extracted text.</p>"},{"location":"Backend/#parameters","title":"Parameters","text":"Parameter Type Required Description url str \u2705 The URL to scrape"},{"location":"Backend/#request-format","title":"Request Format","text":"<p>Send a POST request with a JSON body:</p> <pre><code>{\n  \"url\": \"https://example.com\"\n}\n</code></pre>"},{"location":"Backend/#response-format","title":"Response Format:","text":"<pre><code>{\n    \"html\": \"&lt;html&gt;...&lt;/html&gt;\"\n}\n</code></pre>"},{"location":"Backend/#returns","title":"Returns","text":"<ul> <li>HTML</li> </ul> <p>If an error occurs, returns a JSON object with an error message.</p>"},{"location":"Backend/#scrape_with_bs4","title":"scrape_with_bs4:","text":""},{"location":"Backend/#description_1","title":"Description:","text":"<p>Uses BeautifulSoup to parse and prettify the HTML content. It can also clean the HTML to return readable text</p>"},{"location":"Backend/#parameters_1","title":"Parameters","text":"Parameter Type Required Description url str \u2705 The URL to scrape clean bool \u274c If True, extracts only readable text"},{"location":"Backend/#request-format_1","title":"Request Format","text":"<p>Send a POST request with a JSON body:</p> <pre><code>{\n  \"url\": \"https://example.com\"\n}\n</code></pre>"},{"location":"Backend/#response-format_1","title":"Response Format:","text":"<pre><code>{\n    \"html\": \"&lt;html&gt;...&lt;/html&gt;\"\n}\n</code></pre>"},{"location":"Backend/#returns_1","title":"Returns","text":"<ul> <li>Prettified HTML if clean=False</li> <li>Readable formatted text if clean=True</li> <li>Returns an error message if scraping fails.</li> </ul>"},{"location":"Backend/#scrape_with_selenium","title":"scrape_with_selenium :","text":""},{"location":"Backend/#description_2","title":"Description:","text":"<p>Uses Selenium WebDriver to scrape dynamic web pages that rely on JavaScript execution. It can also clean the HTML to return readable text</p>"},{"location":"Backend/#parameters_2","title":"Parameters","text":"Parameter Type Required Description url str \u2705 The URL of the page to scrape company_name str \u2705 The company name to search for clean bool \u274c If True, extracts only readable text"},{"location":"Backend/#environment-variables","title":"Environment Variables","text":"<p>CHROME_PATH: Path to the Chrome WebDriver executable.</p>"},{"location":"Backend/#returns_2","title":"Returns","text":"<ul> <li>Scraped page title</li> <li>Prettified HTML or clean text, based on clean flag.</li> </ul>"},{"location":"Backend/#how-the-scraper-function-works","title":"\ud83d\udccc How the Scraper Function Works","text":""},{"location":"Backend/#1-scraping-with-requests-scrape_with_requests","title":"1\ufe0f\u20e3 Scraping with Requests (<code>scrape_with_requests</code>)","text":"Step Description 1\ufe0f\u20e3 Send HTTP Request The function sends a request to the URL using <code>requests.get(url)</code>. 2\ufe0f\u20e3 Check Response Status If the response is not <code>200 OK</code>, an error is returned. 3\ufe0f\u20e3 Extract Raw HTML The function retrieves and returns the raw HTML using <code>response.text</code>."},{"location":"Backend/#2-scraping-with-beautifulsoup-scrape_with_bs4","title":"2\ufe0f\u20e3 Scraping with BeautifulSoup (<code>scrape_with_bs4</code>)","text":"Step Description 1\ufe0f\u20e3 Send HTTP Request Requests the webpage's HTML content using <code>requests.get(url)</code>. 2\ufe0f\u20e3 Check Response Status If response isn\u2019t <code>200 OK</code>, an error is returned. 3\ufe0f\u20e3 Parse HTML The function parses the HTML with <code>BeautifulSoup()</code>. 4\ufe0f\u20e3 Clean &amp; Prettify Output Returns cleaned text or formatted HTML using <code>soup.prettify()</code>."},{"location":"Backend/#3-scraping-with-selenium-scrape_with_selenium","title":"3\ufe0f\u20e3 Scraping with Selenium (<code>scrape_with_selenium</code>)","text":"Step Description 1\ufe0f\u20e3 Setup Selenium WebDriver Configures Chrome WebDriver for headless browsing. 2\ufe0f\u20e3 Load Webpage Opens the webpage using <code>driver.get(url)</code>. 3\ufe0f\u20e3 Handle JavaScript &amp; Dynamic Content Waits for JavaScript-rendered elements to load. 4\ufe0f\u20e3 Extract Page Source Retrieves HTML content using <code>driver.page_source</code>. 5\ufe0f\u20e3 Clean &amp; Return Data Parses the HTML with <code>BeautifulSoup</code> or returns raw HTML."},{"location":"Backend/#error-handling","title":"\ud83d\udccc Error Handling","text":"<p>The scraper function handles errors and returns structured JSON responses.</p> Error Type Status Code Example Response Missing URL <code>400 Bad Request</code> <code>json {\"error\": \"URL is required\"}</code> Invalid URL <code>400 Bad Request</code> <code>json {\"error\": \"Failed to retrieve content\"}</code> Request Timeout <code>500 Server Error</code> <code>json {\"error\": \"An error occurred: timeout\"}</code> Parsing Error <code>500 Server Error</code> <code>json {\"error\": \"Failed to parse HTML\"}</code> Selenium WebDriver Error <code>500 Server Error</code> <code>json {\"error\": \"Selenium WebDriver error\"}</code> <p>\u2705 If an error occurs, the function returns a structured JSON error message instead of crashing.</p>"},{"location":"Backend/#comparison-of-scraping-methods","title":"\ud83d\udccc Comparison of Scraping Methods","text":"Method Best For Pros Cons Requests Static websites \u2705 Fast, \u2705 Lightweight \u274c No JavaScript support BeautifulSoup Cleaning &amp; parsing HTML \u2705 Easy to use, \u2705 Lightweight \u274c Needs requests first Selenium JavaScript-heavy pages \u2705 Handles dynamic content \u274c Slower, \u274c Requires WebDriver"},{"location":"Backend/#3-configpy","title":"3. config.py :","text":""},{"location":"Backend/#overview_2","title":"\ud83d\udccc Overview","text":"<p>This module configures the Flask application by:</p> <ul> <li> <p>Loading environment variables from a <code>.env</code> file.</p> </li> <li> <p>Setting up the database connection using SQLAlchemy.</p> </li> <li> <p>Enabling CORS to allow cross-origin requests.</p> </li> <li> <p>Managing security settings with a secret key.</p> </li> </ul>"},{"location":"Backend/#flask-app-initialization","title":"\ud83d\ude80 Flask App Initialization","text":"<pre><code>app = Flask(__name__)  # Create an app instance\nCORS(app)\nCORS(app, supports_credentials=True)\n</code></pre> <ul> <li>CORS (Cross-Origin Resource Sharing) is enabled to allow requests from different domains.</li> <li>supports_credentials=True allows cookies and authentication headers in requests.</li> </ul>"},{"location":"Backend/#environment-variables-env","title":"\ud83d\udd10 Environment Variables (.env)","text":"<ul> <li>This module loads sensitive configurations from a .env file using dotenv.</li> <li>The .env file is not included in version control (Git) to protect sensitive information.</li> </ul> <pre><code>load_dotenv()  # Load environment variables from .env\napp.config[\"SECRET_KEY\"] = os.getenv(\"SECRET_KEY\")\n</code></pre> <ul> <li>SECRET_KEY \u2192 Used for secure sessions and JWT authentication.</li> </ul>"},{"location":"Backend/#database-configuration","title":"\ud83d\uddc4\ufe0f Database Configuration","text":"<pre><code>database_uri = os.getenv(\"DATABASE_URI\")\napp.config[\"SQLALCHEMY_DATABASE_URI\"] = database_uri\napp.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\ndb = SQLAlchemy(app)  # Create a database instance\n</code></pre> <ul> <li>SQLALCHEMY_DATABASE_URI \u2192 Defines the database connection.</li> <li>SQLALCHEMY_TRACK_MODIFICATIONS=False \u2192 Disables unnecessary tracking to improve performance.</li> </ul>"},{"location":"Contact/","title":"\ud83d\udcde Contact Us","text":"<p>If you have any questions, feedback, or need support, feel free to reach out to us.</p>"},{"location":"Contact/#email","title":"\ud83d\udce7 Email","text":"<p>For Backend and Scraping informations, you can email us at: \u2709\ufe0f khadijamami27@gmail.com</p> <p>\u2709\ufe0f aliaqarasikh@gmail.com</p> <p>For Frontend informations, please contact: \u2709\ufe0f margarita.tsatsi@gmail.com</p> <p>\u2709\ufe0f marian-alexandru.tugui@hs-augsburg.de</p>"},{"location":"Frontend/","title":"Frontend Developer Documentation","text":""},{"location":"Frontend/#introduction","title":"Introduction","text":"<p>The Web Scraper Application is a React-based web interface that allows users to extract data from websites using various scraping methods, view and download the results, and manage their scraping history. The frontend communicates with a Flask-based backend API to perform scraping operations, manage user authentication, and store scraping history.</p>"},{"location":"Frontend/#project-setup","title":"\ud83d\udee0\ufe0f Project Setup","text":""},{"location":"Frontend/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Node.js (v16.x or higher)</li> <li>npm (v8.x or higher) or yarn (v1.22.x or higher)</li> </ul>"},{"location":"Frontend/#installation","title":"Installation","text":"<ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/AliRasikh/data-scraping-application.git\ncd data-scraping-application/frontend\n</code></pre> <ol> <li>Install dependencies:</li> </ol> <pre><code>npm install\n# or\nyarn install\n</code></pre> <ol> <li>Create a <code>.env</code> file in the root of the frontend directory with the following content:</li> </ol> <pre><code>VITE_API_BASE_URL=http://localhost:5000\n</code></pre> <pre><code>\ud83d\udd39 Replace the URL with your backend server URL if it's different.\n\n### \ud83d\ude80Running the Development Server\n\nTo start the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n</code></pre> <p>This will start the Vite development server, typically on http://localhost:5173. The application will automatically reload if you make changes to the source files.</p>"},{"location":"Frontend/#building-for-production","title":"\ud83d\udce6 Building for Production","text":"<p>To create a production build:</p> <pre><code>```bash\nnpm run build\n# or\nyarn build\n</code></pre> <p>This will generate optimized files in the <code>dist</code> directory. You can preview the production build locally with:</p> <pre><code>npm run preview\n# or\nyarn preview\n</code></pre>"},{"location":"Frontend/#project-structure","title":"Project Structure","text":"<p>The frontend codebase is organized as follows:</p> <p>frontend/ \u251c\u2500\u2500 public/ # Static assets that don't need processing \u251c\u2500\u2500 src/ # Source code \u2502 \u251c\u2500\u2500 api/ # API communication \u2502 \u251c\u2500\u2500 api/ # API communication \u2502 \u251c\u2500\u2500 components/ # Reusable UI components \u2502 \u251c\u2500\u2500 const/ # Constants, types and utils file \u2502 \u251c\u2500\u2500 pages/ # Page components \u2502 \u251c\u2500\u2500 routes/ # Routing configuration \u2502 \u251c\u2500\u2500 App.tsx # Main application component \u2502 \u2514\u2500\u2500 main.tsx # Application entry point \u251c\u2500\u2500 .env # Environment variables \u251c\u2500\u2500 index.html # HTML template \u251c\u2500\u2500 package.json # Project dependencies and scripts \u251c\u2500\u2500 tsconfig.json # TypeScript configuration \u251c\u2500\u2500 vite.config.ts # Vite configuration \u2514\u2500\u2500 tailwind.config.js # Tailwind CSS configuration</p>"},{"location":"Frontend/#technology-stack","title":"Technology Stack","text":"Step Description 1\ufe0f\u20e3 Login Process400 User submits credentials to /login API. 2\ufe0f\u20e3 Token Storage JWT token is stored in localStorage. 3\ufe0f\u20e3 Authenticated Requests All protected API requests include Authorization: Bearer . 4\ufe0f\u20e3 Logout Process Token is removed from storage. <p>The frontend is built with the following technologies:</p> <ul> <li>React 19: UI library for building component-based interfaces</li> <li>TypeScript: For type safety and enhanced developer experience</li> <li>Vite: Fast, modern frontend build tool</li> <li>React Router v7: For client-side routing</li> <li>Axios: For HTTP requests to the backend API</li> <li>Tailwind CSS: For styling and responsive design</li> <li>Prettier: Code formatting tool for maintaining consistent code style across the project</li> </ul>"},{"location":"Frontend/#application-architecture","title":"Application Architecture","text":""},{"location":"Frontend/#routing","title":"Routing","text":"<p>The application uses React Router v7 for handling client-side routing. The routes are defined in <code>src/routes/AppRoutes.tsx</code>:</p> <pre><code>```typescript\n// src/routes/AppRoutes.tsx\nimport { Routes, Route } from \"react-router-dom\";\nimport ScrapePage from \"../pages/ScrapePage\";\nimport Login from \"../pages/Login\";\nimport SignUpPage from \"../pages/SignUpPage\";\nimport HistoryPage from \"../pages/HistoryPage\";\n\nconst AppRoutes = () =&gt; {\n  return (\n    &lt;Routes&gt;\n      &lt;Route path=\"/\" element={&lt;ScrapePage /&gt;} /&gt;\n      &lt;Route path=\"/login\" element={&lt;Login /&gt;} /&gt;\n      &lt;Route path=\"/signup\" element={&lt;SignUpPage /&gt;} /&gt;\n      &lt;Route path=\"/history\" element={&lt;HistoryPage /&gt;} /&gt;\n    &lt;/Routes&gt;\n  );\n};\n\nexport default AppRoutes;\n</code></pre> <p>For persistent state across sessions:</p> <p>Authentication state is stored in localStorage to persist across page refreshes and browser sessions:</p> <ul> <li><code>isAuthenticated</code>: Boolean flag indicating if a user is logged in</li> <li><code>authToken</code>: JWT token used for authenticated API requests</li> </ul> <p>Example of state management in components:</p> <pre><code>```typescript\n// Local component state with useState\nconst [urlInput, setUrlInput] = useState&lt;string | undefined&gt;(undefined);\nconst [isLoading, setIsLoading] = useState&lt;boolean&gt;(false);\nconst [error, setError] = useState&lt;string | undefined&gt;(undefined);\n\n// Side effects with useEffect\nuseEffect(() =&gt; {\n  // Check authentication on component mount\n  const isAuthenticated = localStorage.getItem(\"isAuthenticated\") === \"true\";\n  if (!isAuthenticated) {\n    navigate(\"/login\");\n    return;\n  }\n\n  // Fetch data from API\n  fetchData();\n\n  // Cleanup function (runs on component unmount)\n  return () =&gt; {\n    // Cleanup operations if needed\n  };\n}, [navigate]); // Dependencies array\n</code></pre>"},{"location":"Frontend/#api-communication","title":"API Communication","text":"<pre><code>The application communicates with the backend API using Axios. The API integration is configured in `src/api/axios.ts` and `src/api/globalvariables.ts`.\n\n#### Base URL Configuration\n\n```typescript\n```typescript\n// src/api/globalvariables.ts\nexport const BASE_URL = import.meta.env.VITE_API_BASE_URL;\n</code></pre> <pre><code>#### API Requests\n\n```typescript\n```typescript\n// src/api/axios.ts\nimport axios from \"axios\";\n\nexport const sendAxiosRequest = async (url: string, data: object) =&gt; {\n  try {\n    const response = await axios.post(url, data, {\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n    });\n    return response.data;\n  } catch (error) {\n    console.error(\"Error:\", error);\n    throw error;\n  }\n};\n</code></pre> <p>// More utility functions for file handling...</p> <pre><code>## Components Overview\n\n### Pages\n\n#### ScrapePage.tsx\n\nThe main page where users can input a URL, select a scraping method, and execute scraping operations.\n\n**Key Features:**\n\n- URL input with validation\n- Scraping method selection (Requests, BeautifulSoup, Selenium)\n- Optional data cleaning and company name input for Selenium\n- Loading state during scraping\n- Preview and download functionality for scraped content\n\n**Key State Variables:**\n\n```typescript\nconst [urlInput, setUrlInput] = useState&lt;string | undefined&gt;(undefined);\nconst [selectedOption, setSelectedOption] = useState&lt;RadioOption&gt;(\"requests\");\nconst [cleanData, setCleanData] = useState&lt;boolean&gt;(false);\nconst [companyName, setCompanyName] = useState&lt;string&gt;(\"\");\nconst [scrapedPage, setScrapedPage] = useState&lt;string | null&gt;(null);\nconst [isLoading, setIsLoading] = useState&lt;boolean&gt;(false);\n</code></pre>"},{"location":"Frontend/#historypagetsx","title":"HistoryPage.tsx","text":"<p>Displays the user's scraping history with color-coded visualization of different scraping methods.</p> <p>Key Features:</p> <ul> <li>Authentication check to redirect unauthenticated users</li> <li>Fetching and displaying scraping history from the backend</li> <li>Color-coded labels for different scraping methods</li> <li>Preview of scraped content</li> <li>Download functionality for previously scraped content</li> </ul> <p>Implementation:</p> <pre><code>// Authentication check\nuseEffect(() =&gt; {\n  const isAuthenticated = localStorage.getItem(\"isAuthenticated\") === \"true\";\n  if (!isAuthenticated) {\n    navigate(\"/login\");\n    return;\n  }\n  fetchHistory();\n}, [navigate]);\n\n// Fetching history\nconst fetchHistory = async () =&gt; {\n  try {\n    // API call to fetch history\n    // Processing and displaying results\n  } catch (err) {\n    // Error handling\n  }\n};\n</code></pre>"},{"location":"Frontend/#logintsx","title":"Login.tsx","text":"<p>Handles user authentication with email and password.</p> <p>Key Features:</p> <ul> <li>Email and password validation</li> <li>Error handling for authentication failures</li> <li>JWT token storage in localStorage</li> <li>Redirection after successful login</li> </ul> <p>Implementation:</p> <pre><code>const signInWithEmail = async () =&gt; {\n  // Validation\n  // API call to backend authentication endpoint\n  // Store token and authentication status\n  // Redirect to main page\n};\n</code></pre> <pre><code>#### SignUpPage.tsx\n\nManages new user registration with form validation.\n\n**Key Features:**\n\n- Form validation for username, email, and password\n- Password confirmation\n- Error handling for registration failures\n- Success feedback and redirection\n\n### Reusable Components\n\n#### Navbar.tsx\n\nNavigation component that appears on all pages, with conditional rendering based on authentication status.\n\n**Implementation:**\n\n```typescript\n// Check authentication status\nuseEffect(() =&gt; {\n  const checkAuth = () =&gt; {\n    const authStatus = localStorage.getItem(\"isAuthenticated\");\n    setIsAuthenticated(authStatus === \"true\");\n  };\n  // Add event listener for auth changes\n  // ...\n}, []);\n\n// Render different links based on auth status\nreturn (\n  &lt;nav&gt;\n    {!isAuthenticated ? (\n      // Links for non-authenticated users\n    ) : (\n      // Links for authenticated users\n    )}\n  &lt;/nav&gt;\n);\n</code></pre> <pre><code>#### LogoutButton.tsx\n\nHandles user logout by clearing authentication state.\n\n**Implementation:**\n\n```typescript\nconst handleLogout = () =&gt; {\n  localStorage.removeItem(\"authToken\");\n  localStorage.removeItem(\"isAuthenticated\");\n  delete axios.defaults.headers.common[\"Authorization\"];\n  navigate(\"/login\");\n};\n</code></pre>"},{"location":"Frontend/#radiobuttonsexampletsx","title":"RadioButtonsExample.tsx","text":"<p>Provides a customizable radio button group for selecting scraping methods, with additional input fields based on selection.</p> <p>Props:</p> <pre><code>type RadioButtonsProps = {\n  setter: Dispatch&lt;SetStateAction&lt;RadioOption&gt;&gt;;\n  getter: string;\n  cleanData: boolean;\n  setCleanData: Dispatch&lt;SetStateAction&lt;boolean&gt;&gt;;\n  companyName: string;\n  setCompanyName: Dispatch&lt;SetStateAction&lt;string&gt;&gt;;\n};\n</code></pre>"},{"location":"Frontend/#authentication-flow","title":"Authentication Flow","text":"<p>The application uses JWT-based authentication:</p> <ol> <li> <p>Login Process:</p> </li> <li> <p>User submits email and password to <code>/login</code> endpoint</p> </li> <li>Backend validates credentials and returns a JWT token</li> <li>Frontend stores token in localStorage and sets <code>isAuthenticated</code> flag</li> <li> <p>Axios is configured to include the token in subsequent requests</p> </li> <li> <p>Authentication Check:</p> </li> <li> <p>Protected pages (like History) verify authentication status on load</p> </li> <li> <p>If not authenticated, redirect to login page</p> </li> <li> <p>Logout Process:</p> </li> <li>Remove token and authentication flag from localStorage</li> <li>Clear authorization headers from Axios</li> <li>Redirect to login page</li> </ol> <p>Example Authentication Check:</p> <pre><code>useEffect(() =&gt; {\n  const isAuthenticated = localStorage.getItem(\"isAuthenticated\") === \"true\";\n  if (!isAuthenticated) {\n    navigate(\"/login\");\n  }\n}, [navigate]);\n</code></pre> <pre><code>**Example API Call with Authentication:**\n\n```typescript\nconst fetchData = async () =&gt; {\n  const token = localStorage.getItem(\"authToken\");\n  if (!token) throw new Error(\"No authentication token found\");\n\n  const response = await axios({\n    method: \"get\",\n    url: `${BASE_URL}/endpoint`,\n    headers: {\n      Authorization: `Bearer ${token}`,\n      \"Content-Type\": \"application/json\",\n    },\n  });\n\n  // Process response...\n};\n</code></pre> <pre><code>## Scraping Functionality\n\nThe application offers three scraping methods, each with different capabilities:\n\n1. **Requests**:\n\n   - Simple HTTP requests to retrieve static content\n   - Fastest method but limited to static websites\n\n2. **Beautiful Soup (BS4)**:\n\n   - HTML parsing and content extraction\n   - Option to clean and format the data\n   - Better for more complex static websites\n\n3. **Selenium**:\n   - Browser automation for dynamic websites\n   - Can interact with JavaScript-driven content\n   - Requires a company name for search functionality\n   - Slowest but most powerful method\n\n**Scraping Process:**\n\n1. User enters a URL and selects a scraping method\n2. Additional options are configured based on the selected method\n3. The scraping request is sent to the backend\n4. Results are displayed with options to preview and download\n\n**Implementation:**\n\n```typescript\nconst handleScrape = async () =&gt; {\n  // Validation\n  try {\n    setIsLoading(true);\n\n    // Prepare request payload based on selected method\n    const payload = {\n      url: urlInput,\n      scraping_method: selectedOption,\n      clean_data: cleanData,\n      company_name: selectedOption === \"selenium\" ? companyName : undefined,\n    };\n\n    // Send request to backend\n    const response = await axios.post(`${BASE_URL}/scrape`, payload, {\n      headers: { Authorization: `Bearer ${token}` },\n    });\n\n    // Process successful response\n    setScrapedPage(response.data.scrape_result);\n  } catch (err) {\n    // Error handling\n  } finally {\n    setIsLoading(false);\n  }\n};\n</code></pre>"},{"location":"Frontend/#code-conventions","title":"Code Conventions","text":"<p>The project follows these coding conventions:</p> <ol> <li> <p>TypeScript Usage:</p> </li> <li> <p>Define interfaces for all props and state</p> </li> <li>Use type assertions when necessary</li> <li> <p>Leverage TypeScript's type checking to prevent runtime errors</p> </li> <li> <p>Component Organization:</p> </li> <li> <p>Pages are stored in <code>src/pages/</code></p> </li> <li>Reusable components are in <code>src/components/</code></li> <li>API integration is in <code>src/api/</code></li> <li> <p>Types and constants are in <code>src/const/</code></p> </li> <li> <p>Naming Conventions:</p> </li> <li> <p>PascalCase for component names and types</p> </li> <li>camelCase for variables, functions, and props</li> <li> <p>File names match the component name (e.g., <code>ScrapePage.tsx</code>)</p> </li> <li> <p>Error Handling:</p> </li> <li> <p>Use try/catch blocks for API calls</p> </li> <li>Set error state for UI feedback</li> <li> <p>Log detailed errors to console for debugging</p> </li> <li> <p>Styling:</p> </li> <li>Use Tailwind CSS utility classes for styling</li> <li>Consistent color scheme with blue as the primary color</li> <li>Responsive design using Tailwind's breakpoint utilities</li> </ol>"},{"location":"Frontend/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Frontend/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<ol> <li> <p>Backend Connection Issues:</p> </li> <li> <p>Check that the backend server is running</p> </li> <li>Verify the <code>VITE_API_BASE_URL</code> in your <code>.env</code> file is correct</li> <li> <p>Check browser console for CORS errors</p> </li> <li> <p>Authentication Problems:</p> </li> <li> <p>Check that the token is being stored correctly in localStorage</p> </li> <li>Verify token format in API requests (should be <code>Bearer &lt;token&gt;</code>)</li> <li> <p>Check token expiration (backend validates token lifetime)</p> </li> <li> <p>Build Issues:</p> </li> <li> <p>Run <code>npm clean-install</code> or <code>yarn install --force</code> to reset dependencies</p> </li> <li>Check TypeScript errors in the console</li> <li> <p>Verify that all required environment variables are set</p> </li> <li> <p>Styling Issues:</p> </li> <li>Make sure Tailwind CSS is properly configured</li> <li>Check for conflicting class names</li> <li>Use browser developer tools to inspect element styles</li> </ol>"},{"location":"Frontend/#development-tips","title":"Development Tips","text":"<ol> <li> <p>Adding New Routes:</p> </li> <li> <p>Create a new page component in <code>src/pages/</code></p> </li> <li>Add the route in <code>src/routes/AppRoutes.tsx</code></li> <li> <p>Add navigation links in <code>Navbar.tsx</code> if needed</p> </li> <li> <p>Adding New API Endpoints:</p> </li> <li> <p>Update or add functions in <code>src/api/axios.ts</code></p> </li> <li>Use the existing pattern for API calls</li> <li> <p>Handle authentication headers for protected endpoints</p> </li> <li> <p>Component Development:</p> </li> <li>Start with defining the props interface</li> <li>Implement the component with appropriate state</li> <li>Add error handling for any asynchronous operations</li> <li>Test the component in isolation before integration</li> </ol>"}]}