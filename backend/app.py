"""
This module provides a Flask web application for scraping static
websites and saving the output to a TXT file.
It includes endpoints for scraping a website,
downloading the scraped content as a TXT file, and managing URLs in a database.
Endpoints:
- /scrape_with_bs4 (POST): Scrapes a static website and returns the raw HTML.
- /download/txt (GET): Downloads the scraped HTML content as a TXT file.

"""

from config import app #, db
from flask import request, jsonify

from core.scraper import scrape_with_bs4, scrape_with_requests
from core.file_handler import scraped_data_to_txt_file, get_txt_file


@app.route("/scrape", methods=["POST"])
def scrape():
    """
    Endpoint to scrape a static website and save the output to a TXT file.
    Expects a JSON body with a "url" key.
    """
    # retrieve the json data from the post request
    data = request.json
    print("received data:", data)
    url = data.get("url")
    scraping_method = data.get("scraping_method")
    print(f"Received URL: {url}, Scraping Method: {scraping_method}")


    # if no url is provides , return an error with http 400 status(bad request)
    if not url:
        return jsonify({"error": "URL is required"}), 400
    if not scraping_method:
        return jsonify({"error": "Scraping method is required"}), 400

    if scraping_method == "requests":
        # call the scrape website func for the scraped result
        raw_html = scrape_with_requests(url)
    elif scraping_method == "bs4":
        # call the scrape website func for the scraped result
        raw_html = scrape_with_bs4(url)
    else:
        return jsonify({"error": "Invalid scraping method"}), 400

    # AICI S-A MODIFICAT:
    # Verificăm dacă `raw_html` este un dicționar cu eroare și returnăm răspunsul JSON
    # if isinstance(raw_html, dict) and "error" in raw_html:
    #     return jsonify(raw_html), 400  # Return JSON error response with status 400
    
    # print(f"Saving to file: {type(raw_html)}")  # Afișează tipul de date al `raw_html`
    # if isinstance(raw_html, dict):
    #     print(f"Dictionary content: {raw_html}")  # Afișează conținutul dacă e `dict`

    scraped_data_to_txt_file(raw_html)


    return (
        jsonify(
            {
                "message": f"URL Scraped with {scraping_method} and content saved to TXT file"
            }
        ),
        201,
    )


@app.route("/download/txt", methods=["GET"])
def download_txt():
    """
    Endpoint to download a text file.

    This route handles GET requests to download a text file generated by the
    get_txt_file function.

    Returns:
        Response: A Flask response object containing the text file.
    """
    txt_file = get_txt_file()
    return txt_file


if __name__ == "__main__":
    with app.app_context():
       # db.create_all()

        app.run(debug=True)

# def url_to_db(url):
#     url: str = Url(url=url)
#     try:
#         db.session.add(url)
#         db.session.commit()
#     except Exception as e:
#         return jsonify({"error": str(e)}), 400

#     return jsonify({"message": "URL stored successfully to database"}), 201


# @app.route("/api/urls", methods=["GET"])
# def get_urls():
#     urls = Url.query.all()
#     json_urls = [url.to_json() for url in urls]

#     return jsonify(json_urls)


# @app.route("/api/remove_url/<int:id>", methods=["DELETE"])
# def remove_url(id: int):
#     url = Url.query.get(id)

#     if not url:
#         return jsonify({"error": "URL not found"}), 404

#     db.session.delete(url)
#     db.session.commit()

#     return jsonify({"message": "URL removed successfully"})
